{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlDbOL0iInqX"
   },
   "source": [
    "### Generating Text from a Character level using RNN\n",
    "\n",
    "* Article : [Andrej_Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgDj8BvNJ0Og"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fit9SvghInqZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Td8IR2cInqc"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 1) Data\n",
    "\n",
    "* We can grab any free text from here : [text](https://www.gutenberg.org/)\n",
    "\n",
    "\n",
    "* We will choose Shakespeare's works for two main reasons :\n",
    "\n",
    "    1) Its a large corpus of text, its usually recommended you have at least a source of 1 million characters total to get realistic text generation\n",
    "\n",
    "    2) It has a very distinctive style. Since the text data uses old style english and is formatted in the style of a stage play, it will be very obvious to us if the model is able to reproduce similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSHww6dDInqd"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOHO3lWQInqh"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r').read()    # read it with mode 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "M3mWCBpMInqk",
    "outputId": "9489de2d-ca69-4f87-e140-43ad401402e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGncVwcmInqn"
   },
   "source": [
    "### `Understanding the Unique Characters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogztbvG1Inqo"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YqvCS6y0Inqs",
    "outputId": "1bcfe26c-a407-4342-b15a-9866e6b5192f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kBfBvGBoInqv",
    "outputId": "27e98511-2523-4aeb-da36-6ff40ba6f844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)            # We need to remember this for the last Dense layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUs996RtInqy"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 2) Text Processing\n",
    "\n",
    "* `Text Vectorization`\n",
    "\n",
    "* `Create Encoding Dictionary`\n",
    "\n",
    "**We know a neural network can't take in the raw_string data, we need to assign numbers to each character**\n",
    "\n",
    "**Let's create two dictionaries that can go from numeric index to character and character to numeric index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrfjnjhWInqz"
   },
   "source": [
    "##### We will use `enumerate logic` : which creates a tuple containing the integer or number for corresponding characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cWDZDGqiInq0",
    "outputId": "f1fa60b1-71fa-40a0-cf96-ce9e34a7dfce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    \n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oouv8HkbInq3"
   },
   "source": [
    "##### Let's create a dictionary where the keys are the characters with some number assigned to them\n",
    "\n",
    "* Using `dictionary comprehension`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTverjsgInq4"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G_SL3bHgInq9",
    "outputId": "ac699ffa-dab8-44e0-8276-7e881abcf1eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82}"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6qCbj_WnInrA",
    "outputId": "31c6a17c-61be-4e84-cf85-55a7040e7343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kn7iaPKrInrC"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QqTpJZnCInrF",
    "outputId": "17702ae7-911a-4b2b-ee93-5a4995c0ce7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7sMbIuMgInrI"
   },
   "source": [
    "##### `Encoding the text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gibf3FDaInrJ"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2-k-_cwGInrM",
    "outputId": "d5e89068-a135-4416-b4e8-f09bee0d20b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ...,  1,  1, 39])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T3BIx0n-InrO",
    "outputId": "18ce4c03-1963-4647-a8fe-9e2cc2af916a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3145728,)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySH5KU34InrR"
   },
   "source": [
    "* So we have almost 5.5 million characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOuQUodLInrS"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0NrL-EIInrV"
   },
   "source": [
    "##### We now have a mapping we can use to go back and forth from characters to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGZT0t0dInrV"
   },
   "outputs": [],
   "source": [
    "sample = text[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_iy8wvXGInrZ",
    "outputId": "8956fdfe-a324-47e2-9856-ba98567dc4e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                     1\\n  From fairest c'"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "lz1mdDdPInrc",
    "outputId": "17f856e8-2873-4d69-b7db-78d9749f1c74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kB2LCsYInre"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 3) Creating Batches\n",
    "\n",
    "Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other\n",
    "\n",
    "* `Understand Text Sequences`\n",
    "\n",
    "        To understand how the sequences are organized and shifted one character forward\n",
    "        \n",
    "\n",
    "* `Creating Batches`        \n",
    "\n",
    "\n",
    "* `Shuffle Batches`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pU1mZ7xhInrf"
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "##### How long the training sequence should be?\n",
    "\n",
    "##### We must make sure that our training sequences are long enough that they will actually grab the general structure of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "jtztLAwjInrg",
    "outputId": "35764a6b-fa14-4881-daca-51204cb193c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWKubEfAInri"
   },
   "outputs": [],
   "source": [
    "line = \"From fairest creatures we desire increase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "2L75iOU_Inrl",
    "outputId": "5c1ae97b-ba48-4e60-b6ec-0c65ea654e97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJl9Gn0-Inro"
   },
   "outputs": [],
   "source": [
    "part_stanza = '''\n",
    "From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Mv6tbSObInrq",
    "outputId": "abd9cd52-c557-4405-e926-8f299ee1d53a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcH-CgATInrs"
   },
   "source": [
    "### `Training Sequences`\n",
    "\n",
    "* The actual text data will be the text sequence shifted one character forward\n",
    "\n",
    "* For Instance :\n",
    "\n",
    "    * Sequence In : 'Hello my nam'\n",
    "    \n",
    "    * Sequence Out : 'ello my name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgBzTUZDInru"
   },
   "outputs": [],
   "source": [
    "seq_len = 120   # choosing a value around (133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdXWpgYIInry"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Total no.of sequences in the Text\n",
    "\n",
    "// is to round off the division value\n",
    "\n",
    "+1 is to include index_0\n",
    "\n",
    "'''\n",
    "\n",
    "total_num_seq = len(text) // (seq_len+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "5DuPpwVpInr0",
    "outputId": "565487a7-724e-46c9-c868-ec52846676f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25997"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGp7v9IEInr3"
   },
   "source": [
    "##### Now let's create the Training sequences \n",
    "\n",
    "* `tf.data.Dataset.from_tensor_slices` function converts a text vector into a stream of character indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIinGrVkInr4"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "8ghkhqYsInr6",
    "outputId": "8f5c57d1-a056-483f-fc6a-2a04761b8430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "E8ei4KvNInr8",
    "outputId": "43d0b11a-6d9f-4100-c3f4-3345ebce1080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(12, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(31, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(45, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(77, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(27, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(71, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(33, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(21, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(27, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(31, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(38, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(66, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(45, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(21, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(45, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(68, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(26, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(67, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "tf.Tensor(80, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(74, shape=(), dtype=int64)\n",
      "tf.Tensor(71, shape=(), dtype=int64)\n",
      "tf.Tensor(73, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(48, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(75, shape=(), dtype=int64)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(70, shape=(), dtype=int64)\n",
      "tf.Tensor(78, shape=(), dtype=int64)\n",
      "tf.Tensor(69, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "tf.Tensor(76, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in char_dataset.take(500):   # take method creates a dataset\n",
    "    \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "uMpP9V0TInr_",
    "outputId": "3105bbe8-d265-4c74-bb01-d9dfe222b4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "12\n",
      "0\n",
      "1\n",
      "1\n",
      "31\n",
      "73\n",
      "70\n",
      "68\n",
      "1\n",
      "61\n",
      "56\n",
      "64\n",
      "73\n",
      "60\n",
      "74\n",
      "75\n",
      "1\n",
      "58\n",
      "73\n",
      "60\n",
      "56\n",
      "75\n",
      "76\n",
      "73\n",
      "60\n",
      "74\n",
      "1\n",
      "78\n",
      "60\n",
      "1\n",
      "59\n",
      "60\n",
      "74\n",
      "64\n",
      "73\n",
      "60\n",
      "1\n",
      "64\n",
      "69\n",
      "58\n",
      "73\n",
      "60\n",
      "56\n",
      "74\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "56\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "73\n",
      "60\n",
      "57\n",
      "80\n",
      "1\n",
      "57\n",
      "60\n",
      "56\n",
      "76\n",
      "75\n",
      "80\n",
      "5\n",
      "74\n",
      "1\n",
      "73\n",
      "70\n",
      "74\n",
      "60\n",
      "1\n",
      "68\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "69\n",
      "60\n",
      "77\n",
      "60\n",
      "73\n",
      "1\n",
      "59\n",
      "64\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "27\n",
      "76\n",
      "75\n",
      "1\n",
      "56\n",
      "74\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "73\n",
      "64\n",
      "71\n",
      "60\n",
      "73\n",
      "1\n",
      "74\n",
      "63\n",
      "70\n",
      "76\n",
      "67\n",
      "59\n",
      "1\n",
      "57\n",
      "80\n",
      "1\n",
      "75\n",
      "64\n",
      "68\n",
      "60\n",
      "1\n",
      "59\n",
      "60\n",
      "58\n",
      "60\n",
      "56\n",
      "74\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "33\n",
      "64\n",
      "74\n",
      "1\n",
      "75\n",
      "60\n",
      "69\n",
      "59\n",
      "60\n",
      "73\n",
      "1\n",
      "63\n",
      "60\n",
      "64\n",
      "73\n",
      "1\n",
      "68\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "57\n",
      "60\n",
      "56\n",
      "73\n",
      "1\n",
      "63\n",
      "64\n",
      "74\n",
      "1\n",
      "68\n",
      "60\n",
      "68\n",
      "70\n",
      "73\n",
      "80\n",
      "21\n",
      "0\n",
      "1\n",
      "1\n",
      "27\n",
      "76\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "70\n",
      "76\n",
      "1\n",
      "58\n",
      "70\n",
      "69\n",
      "75\n",
      "73\n",
      "56\n",
      "58\n",
      "75\n",
      "60\n",
      "59\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "70\n",
      "78\n",
      "69\n",
      "1\n",
      "57\n",
      "73\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "60\n",
      "80\n",
      "60\n",
      "74\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "31\n",
      "60\n",
      "60\n",
      "59\n",
      "5\n",
      "74\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "67\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "5\n",
      "74\n",
      "1\n",
      "61\n",
      "67\n",
      "56\n",
      "68\n",
      "60\n",
      "1\n",
      "78\n",
      "64\n",
      "75\n",
      "63\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "9\n",
      "74\n",
      "76\n",
      "57\n",
      "74\n",
      "75\n",
      "56\n",
      "69\n",
      "75\n",
      "64\n",
      "56\n",
      "67\n",
      "1\n",
      "61\n",
      "76\n",
      "60\n",
      "67\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "38\n",
      "56\n",
      "66\n",
      "64\n",
      "69\n",
      "62\n",
      "1\n",
      "56\n",
      "1\n",
      "61\n",
      "56\n",
      "68\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "78\n",
      "63\n",
      "60\n",
      "73\n",
      "60\n",
      "1\n",
      "56\n",
      "57\n",
      "76\n",
      "69\n",
      "59\n",
      "56\n",
      "69\n",
      "58\n",
      "60\n",
      "1\n",
      "67\n",
      "64\n",
      "60\n",
      "74\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "80\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "61\n",
      "70\n",
      "60\n",
      "8\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "74\n",
      "78\n",
      "60\n",
      "60\n",
      "75\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "1\n",
      "75\n",
      "70\n",
      "70\n",
      "1\n",
      "58\n",
      "73\n",
      "76\n",
      "60\n",
      "67\n",
      "21\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "70\n",
      "76\n",
      "1\n",
      "75\n",
      "63\n",
      "56\n",
      "75\n",
      "1\n",
      "56\n",
      "73\n",
      "75\n",
      "1\n",
      "69\n",
      "70\n",
      "78\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "78\n",
      "70\n",
      "73\n",
      "67\n",
      "59\n",
      "5\n",
      "74\n",
      "1\n",
      "61\n",
      "73\n",
      "60\n",
      "74\n",
      "63\n",
      "1\n",
      "70\n",
      "73\n",
      "69\n",
      "56\n",
      "68\n",
      "60\n",
      "69\n",
      "75\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "26\n",
      "69\n",
      "59\n",
      "1\n",
      "70\n",
      "69\n",
      "67\n",
      "80\n",
      "1\n",
      "63\n",
      "60\n",
      "73\n",
      "56\n",
      "67\n",
      "59\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "62\n",
      "56\n",
      "76\n",
      "59\n",
      "80\n",
      "1\n",
      "74\n",
      "71\n",
      "73\n",
      "64\n",
      "69\n",
      "62\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "48\n",
      "64\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "1\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "70\n",
      "78\n",
      "69\n",
      "1\n",
      "57\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "for item in char_dataset.take(500):\n",
    "    \n",
    "    print(item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "QBYVRuu3InsB",
    "outputId": "4395a13e-5842-4c8b-9dae-8a4802631e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "1\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "u\n",
      "t\n",
      "y\n",
      "'\n",
      "s\n",
      " \n",
      "r\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "H\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "o\n",
      "r\n",
      "y\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "e\n",
      "y\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "e\n",
      "e\n",
      "d\n",
      "'\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "u\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "M\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "w\n",
      "e\n",
      "e\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      " \n",
      "c\n",
      "r\n",
      "u\n",
      "e\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "s\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "A\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "W\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "for item in char_dataset.take(500):\n",
    "    \n",
    "    print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9s1KgiGInsE"
   },
   "source": [
    "##### So now let's create Sequences from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9A12LmWInsE"
   },
   "source": [
    "* `batch` method converts the individual character calls into sequences we can feed in as a batch\n",
    "\n",
    "* `drop_remainder` represents whether or not the last batch should be dropped in the case it has fewer elements than the actual `batch_size` elements; the default behaviour is not to drop the smaller batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrlDKn8kInsF"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpSh8uF0InsH"
   },
   "source": [
    "So now we have our sequences, we will perform the following steps for each one of them to create our target text sequence :\n",
    "\n",
    "* Grab the input text sequence\n",
    "\n",
    "* Assign the target text sequence as the input text sequence shifted by one step forward\n",
    "\n",
    "* Group them together as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aj6jpp3InsI"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    \n",
    "    input_txt = seq[:-1]   # hello my nam\n",
    "    \n",
    "    target_txt = seq[1:]   # ello my name\n",
    "    \n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i32ZBtb4InsK"
   },
   "source": [
    "##### Let's map the function to all the sequences \n",
    "\n",
    "So my final dataset will be :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAJqXe4dInsL"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "qNLHCOJUInsP",
    "outputId": "d60ddf2a-1516-4b8f-e925-f808a2a1eeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in dataset.take(1):\n",
    "    \n",
    "    print(input_txt.numpy())\n",
    "    \n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    \n",
    "    print(target_txt.numpy())\n",
    "    \n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JWdzG0cInsR"
   },
   "source": [
    "* `So now we have all the actual sequences`\n",
    "\n",
    "\n",
    "* `Let's create the training batches`\n",
    "\n",
    "\n",
    "* `We have to shuffle those sequences into a random order, so the model doesn't learn on a particular ordering of the text. It should be any random snippet of the text and the model should start generating the next sequence from it`\n",
    "\n",
    "\n",
    "* `By shuffling, the model doesn't overfit to any section of the text, but can instead generate characters given any seed text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRsB9RE1InsS"
   },
   "outputs": [],
   "source": [
    "batch_size = 128    # 128 sequences feeding into the network at a time\n",
    "\n",
    "buffer_size = 10000\n",
    "\n",
    "'''\n",
    "buffer_size to shuffle the dataset so it doesn't attempt to shuffle the entire dataset in the memory\n",
    "\n",
    "If dealing with the large dataset, it could cause a potential memory error\n",
    "\n",
    "'''\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "nyF8ipeZInsV",
    "outputId": "0be46064-2873-42c1-b4be-94f049dc8c33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFJhzHrRInsY"
   },
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------\n",
    "128 is the no.of sequences\n",
    "\n",
    "each sequence is 120 long\n",
    "\n",
    "first tuple is for input sequence\n",
    "\n",
    "second tuple is for target sequence\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UFpJiJ0InsY"
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 4) Create the Model\n",
    "\n",
    "* Set up the Loss Function\n",
    "\n",
    "* Create the Model\n",
    "\n",
    "    * Embedding layer\n",
    "    \n",
    "    * GRU layer\n",
    "    \n",
    "    * Dense layer\n",
    "    \n",
    "----------------------------------------------------------------------------------------------------------------------------   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_G3SJJERInsZ"
   },
   "source": [
    "* Embeddings are the only way one can transform discrete feature into a vector form\n",
    "\n",
    "* All machine learning algorithms take a vector and return a prediction\n",
    "\n",
    "* Therefore if you have a categorical feature, the only way you can use it in a ML model is by embedding it into a vector\n",
    "\n",
    "* The simplest kind of embedding is one-hot encoding:\n",
    "\n",
    "        1 -> (1, 0, 0)\n",
    "        2 -> (0, 1, 0)\n",
    "        3 -> (0, 0, 1)\n",
    "\n",
    "* We can replace the categorical feature with three possible values with the vectors as above without losing any information\n",
    "\n",
    "* These vectors have as many elements as the number of values of the categorical feature\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "* When your categorical feature has a lot of possible values, it is often better to replace it with embeddings with lower dimensionality\n",
    "\n",
    "* Lower dimensionality gives you two advantages:\n",
    "\n",
    "        It is more computationally efficient, because smaller embeddings require less memory\n",
    "        \n",
    "        It regularizes your model, because the smaller number of parameters your model have, the better it is regularized\n",
    "-------------------------------                \n",
    "\n",
    "* Embeddings are often used to map words to vectors in NLP systems, words represented as vectors can be used as an input for recurrent neural network\n",
    "\n",
    "* Refer this Article : [Word Embedding Layers with Keras](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)\n",
    "\n",
    "* Embeddings are also quite often used in recommendation systems to represent high dimensionality categorical variables like user_id or recommendable_item_id\n",
    "\n",
    "* Refer this Article : [Embeddings for Collaborative Filtering](https://developers.google.com/machine-learning/crash-course/embeddings/motivation-from-collaborative-filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdDgDlKMInsa"
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "````sh\n",
    "````\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(1000, 4))    # 1000 words, 4 dimensions\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "print(model.predict(np.array([[4,8,3]])))\n",
    "\n",
    "\n",
    "o/p :\n",
    "\n",
    "     [[[-0.09090  -0.93339  0.87322  -0.90893]\n",
    "\n",
    "       [-0.09989   0.89879 -0.97079   0.86853]\n",
    "  \n",
    "       [0.468687   0.78346  0.67352   0.42736]]]\n",
    "  \n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-nQqlbaInsa"
   },
   "source": [
    "* The answer is that the embedding layers in TensorFlow completely differ from the the word embedding algorithms, such as word2vec and GloVe. They only share a similar name!\n",
    "\n",
    "\n",
    "* Embedding refers to mapping a high-dimensional sparse feature vector to a dense vector with a much lower dimension. The embedding layer in TensorFlow is just like a look-up table. For instance, assume that there is a 2D tensor in which the first dimension represent the ID of a word and the second dimension represents the dense vector that is going to be learned during the training phase of the neural network. It is notable that you can also use pre-trained word embeddings (e.g., using word2vec) and use them as an input of the network. You can set Trainable argument to False, if you want to use pre-trained embeddings and do not wish to update them during the learning process of your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWDwFTYuInsb"
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "* We based this model architecture off the [DeepMoji](https://deepmoji.mit.edu/) and the original source code can be found [here](https://github.com/bfelbo/DeepMoji)\n",
    "\n",
    "\n",
    "* The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM usually leads to more realisitic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zU_23Q9_Insb"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)            # unique characters\n",
    "\n",
    "embed_dim = 64                     # near to vocab_size (prefer to be lesser than vocab_size)\n",
    "\n",
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGCpkWnjInsf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FjPZugEYInsh"
   },
   "source": [
    "##### `Let's create a function that easily adapts to different variables as shown above :`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuCG50oRInsh"
   },
   "source": [
    "### Setting up Loss Function :\n",
    "\n",
    "* For our loss we will use `sparse categorical crossentropy`, which we can import from Keras. We will also set this as logits=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TN5TwsUInsi"
   },
   "source": [
    "-----------------------------------------------------------------------------------------------------------\n",
    "###### Sparse Categorical CrossEntropy vs Categorical CrossEntropy\n",
    "\n",
    "* `If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings :`\n",
    "\n",
    "                [1,0,0]\n",
    "\n",
    "                [0,1,0] \n",
    "\n",
    "                [0,0,1]\n",
    "                \n",
    "\n",
    "* `But if your targets are integers, use sparse_categorical_crossentropy. Examples of integer encodings :`\n",
    "\n",
    "                1\n",
    "                \n",
    "                2\n",
    "                \n",
    "                3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noluCLxBInsj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krue7ygZInsl"
   },
   "outputs": [],
   "source": [
    "# help(sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lAZzE68Inso"
   },
   "source": [
    "\n",
    "* We can't just pass-in sparse_c_entropy because we have to add logits=True, as we have one-hot encoded if it is False they are not One-hot encoded \n",
    "\n",
    "\n",
    "* As we need to add this, we have to create our own custom function as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tS8z_b3eInsp"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    \n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7b7Lb9NInsr"
   },
   "source": [
    "##### `Adaptable Model Function :`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbI2GqqHInss"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size) :\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    \n",
    "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GGTxiMPInsu"
   },
   "source": [
    "* return_sequences - to include even the last sequence\n",
    "\n",
    "* stateful - to keep the current state\n",
    "\n",
    "* recu_intializer - weight values for the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjSwqLDYInsu"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size=vocab_size, embed_dim=embed_dim, rnn_neurons=rnn_neurons, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "KVvUTkBcInsw",
    "outputId": "2887faf9-aa3f-41a8-e0b8-a0318a86b7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5312      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 83)           85241     \n",
      "=================================================================\n",
      "Total params: 3,451,729\n",
      "Trainable params: 3,451,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URx-A2XmInsy"
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 5) Train the Model\n",
    "\n",
    "* `Let's make sure that everything is ok with our model before we spend too much time on training`\n",
    "\n",
    "\n",
    "* `So let's pass in a batch to confirm that the model predicts some random characters without any training`\n",
    "\n",
    "* `So let's run an input batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7y7mxWR_Insz"
   },
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "  # predict off some random batch\n",
    "  example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKS2dAMNO-KS"
   },
   "source": [
    "* `input_example_batch` is the original sequence and `target_example_batch` is the original sequence shifted forward by 1 character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c6c1BVQNO4wk",
    "outputId": "c32fe4c4-7685-4a73-b7fa-1da2b3171913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 120, 83])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "PIpqGZByPbAv",
    "outputId": "be9509e8-0659-41b5-ac2e-92379270b844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 83), dtype=float32, numpy=\n",
       "array([[ 3.7978380e-03,  6.3308072e-04,  2.6800812e-03, ...,\n",
       "         3.4248736e-03, -5.9183580e-03,  1.8865713e-03],\n",
       "       [-1.8610966e-03,  2.8349934e-03, -9.1890730e-03, ...,\n",
       "         4.8141559e-03,  2.8258939e-03, -2.5631636e-03],\n",
       "       [-6.7382334e-03,  6.8786405e-03, -8.7012798e-03, ...,\n",
       "         1.3493203e-03, -8.8981271e-04, -2.2271080e-03],\n",
       "       ...,\n",
       "       [ 3.1102551e-03, -6.8542780e-03,  2.7509965e-04, ...,\n",
       "        -4.6271598e-04,  3.2786462e-03,  2.0610620e-03],\n",
       "       [ 3.2731490e-03, -7.8187045e-03,  4.3129027e-03, ...,\n",
       "        -4.7275750e-03,  6.2239864e-03, -1.4775491e-05],\n",
       "       [ 8.1839971e-03, -9.8539060e-03,  3.8443143e-03, ...,\n",
       "        -3.0750241e-03,  3.1683266e-03, -9.2872384e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]              # grabbing the very first batch predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4KeB3ldQ39_"
   },
   "source": [
    "##### These values are just probabilities that our model assumes for each concurrent character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1sKNaC0Pc6H"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "D42lEf9nW3HF",
    "outputId": "942eef94-776b-40f1-b584-f85aa02eb54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
       "array([[ 4],\n",
       "       [ 6],\n",
       "       [70],\n",
       "       [27],\n",
       "       [67],\n",
       "       [41],\n",
       "       [10],\n",
       "       [29],\n",
       "       [58],\n",
       "       [51],\n",
       "       [54],\n",
       "       [22],\n",
       "       [74],\n",
       "       [17],\n",
       "       [45],\n",
       "       [78],\n",
       "       [31],\n",
       "       [ 5],\n",
       "       [40],\n",
       "       [61],\n",
       "       [47],\n",
       "       [15],\n",
       "       [15],\n",
       "       [56],\n",
       "       [65],\n",
       "       [23],\n",
       "       [75],\n",
       "       [78],\n",
       "       [ 3],\n",
       "       [49],\n",
       "       [18],\n",
       "       [28],\n",
       "       [61],\n",
       "       [34],\n",
       "       [33],\n",
       "       [78],\n",
       "       [64],\n",
       "       [24],\n",
       "       [49],\n",
       "       [27],\n",
       "       [ 6],\n",
       "       [80],\n",
       "       [33],\n",
       "       [38],\n",
       "       [40],\n",
       "       [47],\n",
       "       [78],\n",
       "       [20],\n",
       "       [30],\n",
       "       [57],\n",
       "       [22],\n",
       "       [62],\n",
       "       [24],\n",
       "       [26],\n",
       "       [52],\n",
       "       [46],\n",
       "       [ 0],\n",
       "       [69],\n",
       "       [32],\n",
       "       [27],\n",
       "       [ 9],\n",
       "       [28],\n",
       "       [48],\n",
       "       [51],\n",
       "       [14],\n",
       "       [74],\n",
       "       [28],\n",
       "       [16],\n",
       "       [18],\n",
       "       [32],\n",
       "       [21],\n",
       "       [ 0],\n",
       "       [69],\n",
       "       [37],\n",
       "       [27],\n",
       "       [37],\n",
       "       [36],\n",
       "       [75],\n",
       "       [25],\n",
       "       [23],\n",
       "       [21],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [19],\n",
       "       [13],\n",
       "       [17],\n",
       "       [13],\n",
       "       [34],\n",
       "       [47],\n",
       "       [53],\n",
       "       [ 6],\n",
       "       [61],\n",
       "       [78],\n",
       "       [ 6],\n",
       "       [71],\n",
       "       [41],\n",
       "       [10],\n",
       "       [61],\n",
       "       [47],\n",
       "       [59],\n",
       "       [15],\n",
       "       [77],\n",
       "       [48],\n",
       "       [44],\n",
       "       [13],\n",
       "       [10],\n",
       "       [58],\n",
       "       [43],\n",
       "       [35],\n",
       "       [49],\n",
       "       [57],\n",
       "       [10],\n",
       "       [72],\n",
       "       [33],\n",
       "       [39],\n",
       "       [51],\n",
       "       [54],\n",
       "       [60],\n",
       "       [33],\n",
       "       [73]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzeRy8-YXAYn"
   },
   "source": [
    "##### Inorder to pass this sort of Array to ind_to char sequence, we need to reshape this Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CgQKpTDW5GS"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()            # Reformat to not to be a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "FJGoaEx7Xi1-",
    "outputId": "7bfa852b-4161-4588-8587-f8b426b07445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6, 70, 27, 67, 41, 10, 29, 58, 51, 54, 22, 74, 17, 45, 78, 31,\n",
       "        5, 40, 61, 47, 15, 15, 56, 65, 23, 75, 78,  3, 49, 18, 28, 61, 34,\n",
       "       33, 78, 64, 24, 49, 27,  6, 80, 33, 38, 40, 47, 78, 20, 30, 57, 22,\n",
       "       62, 24, 26, 52, 46,  0, 69, 32, 27,  9, 28, 48, 51, 14, 74, 28, 16,\n",
       "       18, 32, 21,  0, 69, 37, 27, 37, 36, 75, 25, 23, 21, 10,  6, 19, 13,\n",
       "       17, 13, 34, 47, 53,  6, 61, 78,  6, 71, 41, 10, 61, 47, 59, 15, 77,\n",
       "       48, 44, 13, 10, 58, 43, 35, 49, 57, 10, 72, 33, 39, 51, 54, 60, 33,\n",
       "       73])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices             # Now we have got this in the format of ind_to_char sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "zgXa4pxhXkFd",
    "outputId": "83d52f99-3661-43e8-8ac5-a65396a14c5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['&', '(', 'o', 'B', 'l', 'P', '.', 'D', 'c', 'Z', '_', ';', 's',\n",
       "       '6', 'T', 'w', 'F', \"'\", 'O', 'f', 'V', '4', '4', 'a', 'j', '<',\n",
       "       't', 'w', '\"', 'X', '7', 'C', 'f', 'I', 'H', 'w', 'i', '>', 'X',\n",
       "       'B', '(', 'y', 'H', 'M', 'O', 'V', 'w', '9', 'E', 'b', ';', 'g',\n",
       "       '>', 'A', '[', 'U', '\\n', 'n', 'G', 'B', '-', 'C', 'W', 'Z', '3',\n",
       "       's', 'C', '5', '7', 'G', ':', '\\n', 'n', 'L', 'B', 'L', 'K', 't',\n",
       "       '?', '<', ':', '.', '(', '8', '2', '6', '2', 'I', 'V', ']', '(',\n",
       "       'f', 'w', '(', 'p', 'P', '.', 'f', 'V', 'd', '4', 'v', 'W', 'S',\n",
       "       '2', '.', 'c', 'R', 'J', 'X', 'b', '.', 'q', 'H', 'N', 'Z', '_',\n",
       "       'e', 'H', 'r'], dtype='<U1')"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fz-ITkTcZCKL"
   },
   "source": [
    "##### The above values are just a bunch of random characters since our model has not been trained at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDnOxvPObBZU"
   },
   "source": [
    "##### `After confirming the dimensions are working, we can now train our model :`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nucQDg9oZ2p_"
   },
   "outputs": [],
   "source": [
    "epochs = 30            # 30 epochs atleast to get the realistic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H9XvK4v7bRun",
    "outputId": "77114971-2630-4fce-d2a7-e5839db6e27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 203 steps\n",
      "Epoch 1/30\n",
      "203/203 [==============================] - 18s 90ms/step - loss: 2.8833\n",
      "Epoch 2/30\n",
      "203/203 [==============================] - 17s 85ms/step - loss: 2.0196\n",
      "Epoch 3/30\n",
      "203/203 [==============================] - 17s 85ms/step - loss: 1.7130\n",
      "Epoch 4/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.5208\n",
      "Epoch 5/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.4103\n",
      "Epoch 6/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.3417\n",
      "Epoch 7/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.2943\n",
      "Epoch 8/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.2591\n",
      "Epoch 9/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.2306\n",
      "Epoch 10/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.2068\n",
      "Epoch 11/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.1853\n",
      "Epoch 12/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.1655\n",
      "Epoch 13/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.1465\n",
      "Epoch 14/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.1298\n",
      "Epoch 15/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.1131\n",
      "Epoch 16/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 1.0962\n",
      "Epoch 17/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.0800\n",
      "Epoch 18/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.0644\n",
      "Epoch 19/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.0480\n",
      "Epoch 20/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 1.0333\n",
      "Epoch 21/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 1.0171\n",
      "Epoch 22/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 1.0022\n",
      "Epoch 23/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 0.9868\n",
      "Epoch 24/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 0.9717\n",
      "Epoch 25/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 0.9583\n",
      "Epoch 26/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 0.9451\n",
      "Epoch 27/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 0.9322\n",
      "Epoch 28/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 0.9204\n",
      "Epoch 29/30\n",
      "203/203 [==============================] - 17s 83ms/step - loss: 0.9088\n",
      "Epoch 30/30\n",
      "203/203 [==============================] - 17s 84ms/step - loss: 0.8994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93de833b00>"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4n-6RTngeId"
   },
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 6) Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hs3djDfbXDJ"
   },
   "outputs": [],
   "source": [
    "model.save('shakespeare.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1nKW6zpfzgx"
   },
   "source": [
    "##### `Currently our model only expects 128 sequences at a time. We can create a new model that only expects a batch_size=1`\n",
    "\n",
    "##### `We can create a new model with this batch_size, then load our saved model's weights. Then call .build() on the model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxEqAXHRft8K"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cg9XlwbJj9-C"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('shakespeare.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))      # we will build the model by passing the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "Rx_yCJQLktZ7",
    "outputId": "c3dee2ab-ccad-4392-aeb6-aff094f1dc83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5312      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 83)             85241     \n",
      "=================================================================\n",
      "Total params: 3,451,729\n",
      "Trainable params: 3,451,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0mb9VMuk3X4"
   },
   "source": [
    "##### `Notice that it is the same model summary as earlier but instead of 128 as the batch size now it only expects a batch size of 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-SRs08AlO94"
   },
   "source": [
    "##### Now we can create our own custom function to generate the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfBOZlvsk12H"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed, gen_size=500, temp=1.0) :\n",
    "\n",
    "  '''\n",
    "  model : Trained model to generate text\n",
    "\n",
    "  start_seed : Initial seed text in string form\n",
    "\n",
    "  gen_size : No.of characters to generate\n",
    "\n",
    "  temp : hyper-parameter  used to control the randomness of predictions by scaling the logits before applying softmax\n",
    "\n",
    "  ----------------\n",
    "  \n",
    "  logits are the values to be used as inputs to softmax\n",
    "\n",
    "  sigma ^ -1 (x) is called as logit in statistics, and it stands for the inverse function of logistic sigmoid function\n",
    "\n",
    "  -----------------\n",
    "\n",
    "  Basic idea behind this function is to take in some seed text, \n",
    "\n",
    "  format it so that it is in the correct shape for our network\n",
    "\n",
    "  Then loop the sequence as we keep adding our own predicted characters.\n",
    "\n",
    "  Pretty similar to the work in the RNN time series analysis\n",
    "\n",
    "  '''\n",
    "\n",
    "  num_generate = gen_size\n",
    "\n",
    "  # Vectorizing starting seed text\n",
    "  input_eval = [char_to_ind[s] for s in start_seed]             # for every character will go ahead and transform it to an index and then we will have them in a list\n",
    "\n",
    "  # Expand this to match batch format shape\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty List to hold the resulting generated text\n",
    "  text_generated = []\n",
    "\n",
    "\n",
    "  # Temperature effects randomness in our resulting text\n",
    "  # The term is derived from entropy/thermodynamics.\n",
    "  # The temperature is used to effect probability of next characters.\n",
    "  # Higher probability == lesss surprising/ more expected\n",
    "  # Lower temperature == more surprising / less expected\n",
    "\n",
    "  temperature = temp\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "\n",
    "    # Generate Predictions\n",
    "    predictions = model(input_eval)\n",
    "\n",
    "    # Remove the batch shape dimension\n",
    "    predictions = tf.squeeze(predictions, 0)     # just reverse of expand_dims\n",
    "\n",
    "    # Use a Categorical distribution to select the next character\n",
    "\n",
    "    predictions = predictions/temperature\n",
    "\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "    # Pass the predicted character for the next input\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    # Transform back to character letter\n",
    "    text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return (start_seed + ''.join(text_generated))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "Qq0sfa8_zl6X",
    "outputId": "5dc0f6b5-99b1-4759-da97-7c2a99761c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers on all little\n",
      "    question to emblace,\n",
      "    Shall be emplixt's soul! I entreat you\n",
      "    When you are pantled sleak.  So shape a preparation from our pees\n",
      "    But keep the same-\n",
      "    As Saughter! how made it die?  \n",
      "  MACBETH. O thou thunder after 'tis\n",
      "    sufficient. Get you Cleford; it shall be sufficaing\n",
      "    So half me an alisporation. I'll not be gainged,\n",
      "    And his remembrancer!\n",
      "  ISABELLA. 'dy, Harry, and for an agumblion calls:\n",
      "    I am the restor of them up\n",
      "    That all the Thorning of the dark!\n",
      "     He's dead! Ye will, not fair you.\n",
      "  JAQUES. And I for Bondowinkbet\n",
      "    So worthy of thy outward prepared,\n",
      "    As all the rest, how thou didst met you so?\n",
      "  LADY MACBETH. But, madame, beggars!\n",
      "  'My more divide; that some blood fearful:\n",
      "    'Tis sin to dream! Look how he loses!\n",
      "  Corn. For me no kindness. It is not worth the most care to keep\n",
      "    The shadow of a most. Say what thou hadagon's dake?\n",
      "DROMIO OF SYRACUSE. Besides, they suck overwore to make or pawn upon 's,\n",
      "    An Englishm\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, 'flower', gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SHDQ6pwz2kH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0kB2LCsYInre",
    "pcH-CgATInrs",
    "9UFpJiJ0InsY"
   ],
   "name": "Text-Generation with RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
